{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project is aimed to prepare an in-house datastore that will be mainly manipulated by analysts to discover insights about relations between U.S. immigration data and U.S. city demographic data. Other supplementary datasets may be added to the datastore when requested by analysts.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql.functions import col, udf, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Default limits when displaying Pandas DataFrame.info()\n",
    "# Can be overrided by setting arguments verbose=True and show_counts=True\n",
    "#print(pd.options.display.max_info_columns) # 100\n",
    "#print(pd.options.display.max_info_rows) # 1690785\n",
    "\n",
    "# Default limits when displaying Pandas DataFrame itself\n",
    "#print(pd.options.display.max_columns) # 20\n",
    "#print(pd.options.display.max_rows) # 60\n",
    "\n",
    "# Set options to fully display data contents of Pandas DataFrames on screen\n",
    "# WARNING - Only suitable for small Pandas DataFrames\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.html\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "In this project a local Apache Spark installation will serve as the main datastore of the project. All the tables will be created as the in-memory PySpark DataFrames, and data extracted from original datasets will be loaded into the dataframes. Transformations and other processing will be carried out after the data are successfully loaded into the dataframes.\n",
    "\n",
    "By using Apache Spark and PySpark DataFrames, the final datastore can not only provide SQL quering capabilities, but also offer analysts the flexibility to wrangle with original raw data if needed.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "Following is the datasets that will be used in the project:\n",
    "\n",
    "* [I94 Immigration Data](https://www.trade.gov/i-94-arrivals-historical-data) (This is the main dataset in the project. The [original URL](https://travel.trade.gov/research/reports/i94/historical/2016.html) of the dataset mentioned in the project is now broken, but we can still find an archived copy of the website by using [Wayback Machine](https://web.archive.org/web/20210328153411/https://travel.trade.gov/research/reports/i94/historical/2016.html).)\n",
    "* [U.S. City Demographic Data](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) (This is the additional dataset in the project. It is maintained and provided by [Opendatasoft](https://www.opendatasoft.com/).)\n",
    "\n",
    "Also, these optional datasets are listed here for informational purposes, and will not be utilized in the project.\n",
    "\n",
    "* [World Temperature Data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)\n",
    "* [Airport Code Table](https://datahub.io/core/airport-codes#data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "- I94 Immigration Data\n",
    "    * Wrong data type in various columns. Some of them should be either int or string, but they are being reported as floating numbers instead\n",
    "    * Some of the date columns are [SAS date values](https://v8doc.sas.com/sashtml/lrcon/zenid-63.htm). It would be better if we can change these columns to regular date formats\n",
    "    * NULL value discovered in some columns. These NULL values will be preserved, as they have valid meanings in immigration data\n",
    "\n",
    "\n",
    "- U.S. City Demographic Data\n",
    "    * Wrong data type in several population related columns. These columns should be int type, but most of them are floating numbers.\n",
    "    * NULL value discovered in some columns. These NULL values will be filled with a default zero value, since these columns are numerical by nature, and it would be easier to manipulate the data if we can eliminate the nuisances caused by NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here (we will be using a small sample to explore and assess I94 data)\n",
    "df_i94_data_sample = pd.read_csv('immigration_data_sample.csv')\n",
    "df_us_city_demo = pd.read_csv('us-cities-demographics.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH   NaN   \n",
       "4      3.0      NY  20553.0    19.0      2.0    1.0  20160406      NaN   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       G       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       G       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       G       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "3       G       O      NaN       M   1991.0  10272016      M     NaN      QR   \n",
       "4       Z       K      NaN       M   1997.0  07042016      F     NaN     NaN   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print out first 5 lines of each Pandas DataFrame for a brief check\n",
    "display(df_i94_data_sample.head())\n",
    "display(df_us_city_demo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      "Unnamed: 0    1000 non-null int64\n",
      "cicid         1000 non-null float64\n",
      "i94yr         1000 non-null float64\n",
      "i94mon        1000 non-null float64\n",
      "i94cit        1000 non-null float64\n",
      "i94res        1000 non-null float64\n",
      "i94port       1000 non-null object\n",
      "arrdate       1000 non-null float64\n",
      "i94mode       1000 non-null float64\n",
      "i94addr       941 non-null object\n",
      "depdate       951 non-null float64\n",
      "i94bir        1000 non-null float64\n",
      "i94visa       1000 non-null float64\n",
      "count         1000 non-null float64\n",
      "dtadfile      1000 non-null int64\n",
      "visapost      382 non-null object\n",
      "occup         4 non-null object\n",
      "entdepa       1000 non-null object\n",
      "entdepd       954 non-null object\n",
      "entdepu       0 non-null float64\n",
      "matflag       954 non-null object\n",
      "biryear       1000 non-null float64\n",
      "dtaddto       1000 non-null object\n",
      "gender        859 non-null object\n",
      "insnum        35 non-null float64\n",
      "airline       967 non-null object\n",
      "admnum        1000 non-null float64\n",
      "fltno         992 non-null object\n",
      "visatype      1000 non-null object\n",
      "dtypes: float64(15), int64(2), object(12)\n",
      "memory usage: 226.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data types and NULL values of I94 immigration data sample\n",
    "df_i94_data_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data types and NULL values of US city demographic data\n",
    "df_us_city_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DROP Pandas DataFrames we created to free memory\n",
    "# https://stackoverflow.com/questions/32247643/how-to-delete-multiple-pandas-python-dataframes-from-memory-to-save-ram\n",
    "del df_i94_data_sample\n",
    "\n",
    "# df_us_city_demo will not be dropped, since it will be used as a dataset to load into a Pyspark DataFrame\n",
    "spark_df_us_city_demo = spark.createDataFrame(df_us_city_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat appended.\n",
      "File /data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat appended.\n"
     ]
    }
   ],
   "source": [
    "# Combine I94 SAS data files into parquet files\n",
    "# (code snippet borrowed from Project 1 ETL script)\n",
    "i94_filepath='/data/18-83510-I94-Data-2016/'\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(i94_filepath):\n",
    "    files = glob.glob(os.path.join(root,'*.sas7bdat'))\n",
    "    for f in files :\n",
    "        all_files.append(os.path.abspath(f))\n",
    "\n",
    "for file in all_files:\n",
    "    # Load I94 SAS files into a temp Pyspark DataFrame and write it to parquet files in append mode, one by one\n",
    "    spark_df_sas_temp = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "    spark_df_sas_temp.write.mode('append').parquet('./sas_data')\n",
    "    print(\"File {} appended.\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load combined I94 parquet data files into Pyspark DataFrame\n",
    "spark_df_i94_data = spark.read.parquet('./sas_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+-------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|insnum|airline|       admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+-------------+-----+--------+\n",
      "|5680949.0|2016.0|   7.0| 117.0| 117.0|    NYC|20659.0|    1.0|     NY|   null|  30.0|    3.0|  1.0|20160724|     NPL| null|      G|   null|   null|   null| 1986.0|    D/S|     F|  null|     IG|2.947450085E9| 3940|      F1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+-------------+-----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_i94_data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cicid=5680949.0, i94yr=2016.0, i94mon=7.0, i94cit=117.0, i94res=117.0, i94port='NYC', arrdate=20659.0, i94mode=1.0, i94addr='NY', depdate=None, i94bir=30.0, i94visa=3.0, count=1.0, dtadfile='20160724', visapost='NPL', occup=None, entdepa='G', entdepd=None, entdepu=None, matflag=None, biryear=1986.0, dtaddto='D/S', gender='F', insnum=None, airline='IG', admnum=2947450085.0, fltno='3940', visatype='F1')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df_i94_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_i94_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+--------+-------+-------+--------+-------+-------+-------+-------+--------+-------+------+------+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|   occup|entdepa|entdepd| entdepu|matflag|biryear|dtaddto| gender|  insnum|airline|admnum| fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+--------+-------+-------+--------+-------+-------+-------+-------+--------+-------+------+------+--------+\n",
      "|    0|    0|     0| 28575|     0|      0|      0|  73949|2027926|3308012|  9517|      0|    0|  131050|24032175|40597574|   2404|3287909|40777323|3219581|   9517| 101551|4079983|35678095|1308066|     0|333922|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+--------+-------+-------+--------+-------+-------+-------+-------+--------+-------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://sparkbyexamples.com/pyspark/pyspark-find-count-of-null-none-nan-values/\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "spark_df_i94_data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in spark_df_i94_data.columns]).show()\n",
    "\n",
    "# It turns out that the full I94 dataset does contain some NULL values in the column 'depdate'. Actually this is \n",
    "# a reasonable result, as visitors coming to US may still stay in the US territory when the dataset was \n",
    "# being recorded. However, these NULL values will cause some troubles when we uniformly convert SAS date values to \n",
    "# regular date format data. Because of that, some conditional processing mechanism may be needed when performing \n",
    "# the SAS date conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load raw data from I94_SAS_Labels_Descriptions.SAS file into Pyspark DataFrames in 3 steps\n",
    "# Step 1 : Save raw data as Python dict objects (code snippets borrowed from Udacity Knowledge)\n",
    "# https://knowledge.udacity.com/questions/801811\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')\n",
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic\n",
    "i94cit_res = code_mapper(f_content, \"i94cntyl\")\n",
    "i94port = code_mapper(f_content, \"i94prtl\")\n",
    "i94mode = code_mapper(f_content, \"i94model\")\n",
    "i94addr = code_mapper(f_content, \"i94addrl\")\n",
    "i94visa_cat = {\n",
    "'1':'Business', \n",
    "'2': 'Pleasure', \n",
    "'3' : 'Student'}\n",
    "\n",
    "# https://www.trade.gov/i-94-arrivals-program\n",
    "i94visa_type = {\n",
    "'B1':'Visa Holder: Non-Immigrant Temporary Visitor for Business', \n",
    "'WB':'Visa Waiver Program: Temporary Visitor for Business admitted without a Visa', \n",
    "'GB':'Visa Waiver Program: Guam Visa Waiver Business', \n",
    "'GMB':'Guam Marianas Business', \n",
    "'I':'Visa Holder: Foreign Professional Journalist, Information Media, including Spouse and Child', \n",
    "'I1':'Visa Holder: Foreign Professional Journalist, Information Media, including Spouse and Child', \n",
    "'E1':'Visa Holder: Treaty Trader based on the Trade Treaty between the U.S. and Home Country', \n",
    "'E2':'Visa Holder: Treaty Investor based on the Treaty between the U.S. and Home Country', \n",
    "'B2':'Visa Holder: Non-Immigrant Temporary Visitor for Pleasure', \n",
    "'WT':'Visa Waiver Program: Temporary Visitor for Pleasure admitted without a Visa', \n",
    "'GT':'Visa Waiver Program: Guam Visa Waiver Tourist', \n",
    "'GMT':'Guam Marianas Tourist', \n",
    "'CP':'Parolee (Public Interest – Headquarters) (urgent, medical, family needs) (country code not equal to 584 “Cuba”)', \n",
    "'CPL':'Silent Parolee (do not disclose)', \n",
    "'SBP':'Silent Parolee at POE – CBP', \n",
    "'F1':'Visa Holder: Non-Immigrant Student and Exchange Visitor - Academic Student', \n",
    "'F2':'Visa Holder: Spouse or Child of Academic Student', \n",
    "'M1':'Visa Holder: Student pursuing a full course of study at an established vocational or other recognized non-academic institution (other than in a language training program)', \n",
    "'M2':'Visa Holder: Spouse or Child of M-1 Vocational Student'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 2 : Convert Python dict objects to Pandas DataFrames\n",
    "df_i94cit_res   = pd.DataFrame(i94cit_res, index=[0]).transpose().reset_index().rename(columns={'index':'country_code', 0:'country_name'})\n",
    "df_i94port      = pd.DataFrame(i94port, index=[0]).transpose().reset_index().rename(columns={'index':'airport_code', 0:'airport_location'})\n",
    "df_i94mode      = pd.DataFrame(i94mode, index=[0]).transpose().reset_index().rename(columns={'index':'entry_code', 0:'entry_mode'})\n",
    "df_i94addr      = pd.DataFrame(i94addr, index=[0]).transpose().reset_index().rename(columns={'index':'state_code', 0:'state_name'})\n",
    "df_i94visa_cat  = pd.DataFrame(i94visa_cat, index=[0]).transpose().reset_index().rename(columns={'index':'visa_cat_code', 0:'visa_cat_desc'})\n",
    "df_i94visa_type = pd.DataFrame(i94visa_type, index=[0]).transpose().reset_index().rename(columns={'index':'visa_type_code', 0:'visa_type_desc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Step 3 : Convert Pandas DataFrames to PySpark DataFrames\n",
    "# https://www.geeksforgeeks.org/how-to-convert-pandas-to-pyspark-dataframe/\n",
    "spark_df_i94cit_res   = spark.createDataFrame(df_i94cit_res)\n",
    "spark_df_i94port      = spark.createDataFrame(df_i94port)\n",
    "spark_df_i94mode      = spark.createDataFrame(df_i94mode)\n",
    "spark_df_i94addr      = spark.createDataFrame(df_i94addr)\n",
    "spark_df_i94visa_cat  = spark.createDataFrame(df_i94visa_cat)\n",
    "spark_df_i94visa_type = spark.createDataFrame(df_i94visa_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data\n",
    "\n",
    "* I94 Immigration Data\n",
    "    - Correcting the data types in the columns\n",
    "    - Changing SAS date to YYYY-MM-DD format\n",
    "\n",
    "\n",
    "* U.S. City Demographic Data\n",
    "    - Correcting the data types in the columns\n",
    "    - Changing null values in numerical fields to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform type conversion on i94_data\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-cast-column-type/\n",
    "# https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.withColumn.html\n",
    "spark_df_i94_data = spark_df_i94_data.\\\n",
    "                  withColumn(\"cicid\", spark_df_i94_data.cicid.cast('int')).\\\n",
    "                  withColumn(\"i94yr\", spark_df_i94_data.i94yr.cast('int')).\\\n",
    "                  withColumn(\"i94mon\", spark_df_i94_data.i94mon.cast('int')).\\\n",
    "                  withColumn(\"i94cit\", spark_df_i94_data.i94cit.cast('int').cast('string')).\\\n",
    "                  withColumn(\"i94res\", spark_df_i94_data.i94res.cast('int').cast('string')).\\\n",
    "                  withColumn(\"arrdate\", spark_df_i94_data.arrdate.cast('int')).\\\n",
    "                  withColumn(\"i94mode\", spark_df_i94_data.i94mode.cast('int').cast('string')).\\\n",
    "                  withColumn(\"depdate\", spark_df_i94_data.depdate.cast('int')).\\\n",
    "                  withColumn(\"i94bir\", spark_df_i94_data.i94bir.cast('int').cast('string')).\\\n",
    "                  withColumn(\"i94visa\", spark_df_i94_data.i94visa.cast('int').cast('string')).\\\n",
    "                  withColumn(\"count\", col(\"count\").cast('int')).\\\n",
    "                  withColumn(\"dtadfile\", to_date(col(\"dtadfile\"), \"yyyyMMdd\")).\\\n",
    "                  withColumn(\"biryear\", spark_df_i94_data.biryear.cast('int')).\\\n",
    "                  withColumn(\"dtaddto\", to_date(col(\"dtaddto\"), \"MMddyyyy\")).\\\n",
    "                  withColumn(\"admnum\", spark_df_i94_data.admnum.cast('int').cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform SAS date format conversion on i94_data\n",
    "# https://knowledge.udacity.com/questions/741863\n",
    "# https://stackoverflow.com/questions/26923564/convert-sas-numeric-to-python-datetime\n",
    "# https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.functions.udf.html\n",
    "sasdate_convert = udf(lambda x: datetime.datetime(1960, 1, 1) + datetime.timedelta(days=x) if x else None, returnType=types.DateType())\n",
    "\n",
    "spark_df_i94_data = spark_df_i94_data.\\\n",
    "                  withColumn(\"arrdate\", sasdate_convert(spark_df_i94_data.arrdate)).\\\n",
    "                  withColumn(\"depdate\", sasdate_convert(spark_df_i94_data.depdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform type conversion, NULL value filling, column renaming on us_city_demo\n",
    "spark_df_us_city_demo = spark_df_us_city_demo.\\\n",
    "                      withColumn(\"Male Population\", col(\"Male Population\").cast('int')).\\\n",
    "                      withColumn(\"Female Population\", col(\"Female Population\").cast('int')).\\\n",
    "                      withColumn(\"Number of Veterans\", col(\"Number of Veterans\").cast('int')).\\\n",
    "                      withColumn(\"Foreign-born\", col(\"Foreign-born\").cast('int')).\\\n",
    "                      withColumn(\"Average Household Size\", col(\"Average Household Size\").cast('int'))\n",
    "\n",
    "spark_df_us_city_demo = spark_df_us_city_demo.fillna(\n",
    "    {'Male Population':0, \\\n",
    "     'Female Population':0, \\\n",
    "     'Number of Veterans':0, \\\n",
    "     'Foreign-born':0, \\\n",
    "     'Average Household Size':0}\n",
    ")\n",
    "\n",
    "spark_df_us_city_demo = spark_df_us_city_demo.\\\n",
    "                      withColumnRenamed(\"City\", \"city\").\\\n",
    "                      withColumnRenamed(\"State\", \"state\").\\\n",
    "                      withColumnRenamed(\"Median Age\", \"median_age\").\\\n",
    "                      withColumnRenamed(\"Male Population\", \"male_population\").\\\n",
    "                      withColumnRenamed(\"Female Population\", \"female_population\").\\\n",
    "                      withColumnRenamed(\"Total Population\", \"total_population\").\\\n",
    "                      withColumnRenamed(\"Number of Veterans\", \"number_of_veterans\").\\\n",
    "                      withColumnRenamed(\"Foreign-born\", \"foreign_born\").\\\n",
    "                      withColumnRenamed(\"Average Household Size\", \"average_household_size\").\\\n",
    "                      withColumnRenamed(\"State Code\", \"state_code\").\\\n",
    "                      withColumnRenamed(\"Race\", \"race\").\\\n",
    "                      withColumnRenamed(\"Count\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "We will create a star schema to optimize queries focused on analysis of US immigration data and US city demographic data. Eventually the following tables would be created.\n",
    "\n",
    "Fact Table\n",
    "\n",
    "**i94_data** - I94 Immigration Data\n",
    "* *cicid, i94yr, i94mon, i94cit, i94res, i94port, arrdate, i94mode, i94addr, depdate, i94bir, i94visa, count, dtadfile, visapost, occup, entdepa, entdepd, entdepu, matflag, biryear, dtaddto, gender, insnum, airline, admnum, fltno, visatype*\n",
    "\n",
    "Dimension Tables\n",
    "\n",
    "**i94cit_res** - country codes of COC (Country of Citizenship) and COR (Country of Residence)\n",
    "* *country_code, country_name*\n",
    "\n",
    "**i94port** - simplified version of airport code list\n",
    "* *airport_code, airport_location*\n",
    "\n",
    "**i94mode** - the method how a traveller enters the United States\n",
    "* *entry_code, entry_mode*\n",
    "\n",
    "**i94addr** - simplified version of demographic data\n",
    "* *state_code, state_name*\n",
    "\n",
    "**i94visa_cat** - list of visa categories\n",
    "* *visa_cat_code, visa_cat_desc*\n",
    "\n",
    "**i94visa_type** - class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n",
    "* *visa_type_code, visa_type_desc*\n",
    "\n",
    "**us_city_demo** - U.S. City Demographic Data\n",
    "* *city, state, median_age, male_population, female_population, total_population, number_of_veterans, foreign_born, average_household_size, state_code, race, count*\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Gather necessary datasets (all the raw data files that may be needed by the analysts)\n",
    "2. Load (Extract) the raw data into some staging area. Depending on the choice of the software, it may be some temporary database tables, or some in-memory dataframes\n",
    "3. Assess the loaded data and perform any necessary cleaning/conversion tasks (Transform) before making the data public\n",
    "4. Move the prepared, ready-for-use data to some permanent, non-volatile storage and make the data available for normal use (aka \"Load\" phase in ETL process). Depending on the choice of the software, this step may save the data to another set of permanent database tables, or save the in-memory dataframes to some data files written in some portable formats (eg. Parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_i94_data.createOrReplaceTempView(\"i94_data\")\n",
    "\n",
    "table_i94_data = spark.sql(\"\"\"\n",
    "SELECT cicid, i94yr, i94mon, i94cit, i94res, i94port, arrdate, i94mode, i94addr, depdate, i94bir, i94visa, count, dtadfile, visapost, occup, entdepa, entdepd, entdepu, matflag, biryear, dtaddto, gender, insnum, airline, admnum, fltno, visatype\n",
    "FROM i94_data\n",
    "\"\"\")\n",
    "\n",
    "table_i94_data.write.parquet('/home/workspace/parquet/table_i94_data', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_i94cit_res.createOrReplaceTempView(\"i94cit_res\")\n",
    "\n",
    "table_i94cit_res = spark.sql(\"\"\"\n",
    "SELECT country_code, country_name\n",
    "FROM i94cit_res\n",
    "\"\"\")\n",
    "\n",
    "table_i94cit_res.write.parquet('/home/workspace/parquet/table_i94cit_res', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_i94port.createOrReplaceTempView(\"i94port\")\n",
    "\n",
    "table_i94port = spark.sql(\"\"\"\n",
    "SELECT airport_code, airport_location\n",
    "FROM i94port\n",
    "\"\"\")\n",
    "\n",
    "table_i94cit_res.write.parquet('/home/workspace/parquet/table_i94port', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_i94mode.createOrReplaceTempView(\"i94mode\")\n",
    "\n",
    "table_i94mode = spark.sql(\"\"\"\n",
    "SELECT entry_code, entry_mode\n",
    "FROM i94mode\n",
    "\"\"\")\n",
    "\n",
    "table_i94mode.write.parquet('/home/workspace/parquet/table_i94mode', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_i94addr.createOrReplaceTempView(\"i94addr\")\n",
    "\n",
    "table_i94addr = spark.sql(\"\"\"\n",
    "SELECT state_code, state_name\n",
    "FROM i94addr\n",
    "\"\"\")\n",
    "\n",
    "table_i94addr.write.parquet('/home/workspace/parquet/table_i94addr', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_i94visa_cat.createOrReplaceTempView(\"i94visa_cat\")\n",
    "\n",
    "table_i94visa_cat = spark.sql(\"\"\"\n",
    "SELECT visa_cat_code, visa_cat_desc\n",
    "FROM i94visa_cat\n",
    "\"\"\")\n",
    "\n",
    "table_i94visa_cat.write.parquet('/home/workspace/parquet/table_i94visa_cat', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_i94visa_type.createOrReplaceTempView(\"i94visa_type\")\n",
    "\n",
    "table_i94visa_type = spark.sql(\"\"\"\n",
    "SELECT visa_type_code, visa_type_desc\n",
    "FROM i94visa_type\n",
    "\"\"\")\n",
    "\n",
    "table_i94visa_type.write.parquet('/home/workspace/parquet/table_i94visa_type', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df_us_city_demo.createOrReplaceTempView(\"us_city_demo\")\n",
    "\n",
    "table_us_city_demo = spark.sql(\"\"\"\n",
    "SELECT city, state, median_age, male_population, female_population, total_population, number_of_veterans, foreign_born, average_household_size, state_code, race, count\n",
    "FROM us_city_demo\n",
    "\"\"\")\n",
    "\n",
    "table_us_city_demo.write.parquet('/home/workspace/parquet/table_us_city_demo', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in table i94_data is: 40790529\n",
      "Total number of rows in table i94cit_res is: 289\n",
      "Total number of rows in table i94port is: 660\n",
      "Total number of rows in table i94mode is: 4\n",
      "Total number of rows in table i94addr is: 55\n",
      "Total number of rows in table i94visa_cat is: 3\n",
      "Total number of rows in table i94visa_type is: 19\n",
      "Total number of rows in table us_city_demo is: 2891\n"
     ]
    }
   ],
   "source": [
    "# Check the number of records loaded into each dataframe, should be greater than zero\n",
    "# https://www.geeksforgeeks.org/get-number-of-rows-and-columns-of-pyspark-dataframe/\n",
    "print('Total number of rows in table {} is: {}'.format('i94_data', spark_df_i94_data.count()))\n",
    "\n",
    "print('Total number of rows in table {} is: {}'.format('i94cit_res', spark_df_i94cit_res.count()))\n",
    "print('Total number of rows in table {} is: {}'.format('i94port', spark_df_i94port.count()))\n",
    "print('Total number of rows in table {} is: {}'.format('i94mode', spark_df_i94mode.count()))\n",
    "print('Total number of rows in table {} is: {}'.format('i94addr', spark_df_i94addr.count()))\n",
    "print('Total number of rows in table {} is: {}'.format('i94visa_cat', spark_df_i94visa_cat.count()))\n",
    "print('Total number of rows in table {} is: {}'.format('i94visa_type', spark_df_i94visa_type.count()))\n",
    "\n",
    "print('Total number of rows in table {} is: {}'.format('us_city_demo', spark_df_us_city_demo.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+-------+------+------+-------+------+-----+--------+\n",
      "\n",
      "+------------+------------+\n",
      "|country_code|country_name|\n",
      "+------------+------------+\n",
      "+------------+------------+\n",
      "\n",
      "+------------+----------------+\n",
      "|airport_code|airport_location|\n",
      "+------------+----------------+\n",
      "+------------+----------------+\n",
      "\n",
      "+----------+----------+\n",
      "|entry_code|entry_mode|\n",
      "+----------+----------+\n",
      "+----------+----------+\n",
      "\n",
      "+----------+----------+\n",
      "|state_code|state_name|\n",
      "+----------+----------+\n",
      "+----------+----------+\n",
      "\n",
      "+-------------+-------------+\n",
      "|visa_cat_code|visa_cat_desc|\n",
      "+-------------+-------------+\n",
      "+-------------+-------------+\n",
      "\n",
      "+--------------+--------------+\n",
      "|visa_type_code|visa_type_desc|\n",
      "+--------------+--------------+\n",
      "+--------------+--------------+\n",
      "\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|city|state|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|average_household_size|state_code|race|count|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if there is any NULL value found in the columns which would be declared as primary keys in a SQL database\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-filter-rows-with-null-values/\n",
    "spark_df_i94_data.filter(\"cicid IS NULL\").show()\n",
    "\n",
    "spark_df_i94cit_res.filter(\"country_code IS NULL\").show()\n",
    "spark_df_i94port.filter(\"airport_code IS NULL\").show()\n",
    "spark_df_i94mode.filter(\"entry_code IS NULL\").show()\n",
    "spark_df_i94addr.filter(\"state_code IS NULL\").show()\n",
    "spark_df_i94visa_cat.filter(\"visa_cat_code IS NULL\").show()\n",
    "spark_df_i94visa_type.filter(\"visa_type_code IS NULL\").show()\n",
    "\n",
    "spark_df_us_city_demo.filter(\"city IS NULL OR state IS NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Table *i94_data*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Field      | Description |\n",
    "| ---------- | ----------- |\n",
    "| cicid      | CIC Record ID |\n",
    "| i94yr      | 4 digit year |\n",
    "| i94mon     | Numeric month |\n",
    "| i94cit     | Country of citizenship (COC) |\n",
    "| i94res     | Country of residence (COR) |\n",
    "| i94port    | Airport code |\n",
    "| arrdate    | Arrival Date |\n",
    "| i94mode    | Mode of Transport |\n",
    "| i94addr    | First Address |\n",
    "| depdate    | Departure Date |\n",
    "| i94bir     | Age of Respondent in Years |\n",
    "| i94visa    | Visa codes collapsed into three categories |\n",
    "| count      | Used for summary statistics |\n",
    "| dtadfile   | Character Date Field - Date added to I-94 Files - CIC does not use |\n",
    "| visapost   | Department of State where where Visa was issued - CIC does not use |\n",
    "| occup      | Occupation that will be performed in U.S. - CIC does not use |\n",
    "| entdepa    | Arrival Flag - admitted or paroled into the U.S. - CIC does not use |\n",
    "| entdepd    | Departure Flag - Departed, lost I-94 or is deceased - CIC does not use |\n",
    "| entdepu    | Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use |\n",
    "| matflag    | Match flag - Match of arrival and departure records |\n",
    "| biryear    | 4 digit year of birth |\n",
    "| dtaddto    | Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use |\n",
    "| gender     | Non-immigrant sex |\n",
    "| insnum     | INS number |\n",
    "| airline    | Airline used to arrive in U.S. |\n",
    "| admnum     | Admission Number |\n",
    "| fltno      | Flight number of Airline used to arrive in U.S. |\n",
    "| visatype   | Class of admission legally admitting the non-immigrant to temporarily stay in U.S. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Table *us_city_demo*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Field      | Description |\n",
    "| ---------- | ----------- |\n",
    "| city       | US city name |\n",
    "| state        | US state name |\n",
    "| median_age       | Median Age |\n",
    "| male_population       | Male population count |\n",
    "| female_population       | Female population count |\n",
    "| total_population       | Total population count |\n",
    "| num_of_veterans       | Veteran count |\n",
    "| foreign_born       | Foreign born count |\n",
    "| avg_household_size       | Average household size |\n",
    "| state_code       |US state abbreviation |\n",
    "| race       | Race identifier |\n",
    "| count       | Count of individuals of each race |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Table *i94cit_res*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Field      | Description |\n",
    "| ---------- | ----------- |\n",
    "| country_code | 3 digit code of country |\n",
    "| country_name | Name of country |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Table *i94port*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Field      | Description |\n",
    "| ---------- | ----------- |\n",
    "| airport_code | 3 alphabet code of the airport |\n",
    "| airport_location | Detailed location of the airport |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Table *i94mode*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Field      | Description |\n",
    "| ---------- | ----------- |\n",
    "| entry_code | 1 digit code of the mode of transport |\n",
    "| entry_mode | Detailed description of mode of transport |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Table *i94addr*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Field      | Description |\n",
    "| ---------- | ----------- |\n",
    "| state_code | Abbr. of US state |\n",
    "| state_name | Name of US state |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Table *i94visa_cat*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Field      | Description |\n",
    "| ---------- | ----------- |\n",
    "| visa_cat_code | 1 digit code of the visa category |\n",
    "| visa_cat_desc | Description of the visa category |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Table *i94visa_type*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Field      | Description |\n",
    "| ---------- | ----------- |\n",
    "| visa_type_code | 1 ~ 3 alphanumeric code of the visa type |\n",
    "| visa_type_desc | Description of the visa type |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In this project a local Apache Spark installation is being used as the main datastore. Because of the features it offers (SQL-like querying, raw data always available, performance of in-memory dataframes), Spark is quite versatile for the prototyping of the ETL pipelines, and the ETL logics can be ported to other database solutions (SQL-based RDBMS or data warehouse) with moderate efforts when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Propose how often the data should be updated and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I94 Immigration Data is recommended to be updated monthly, because the raw data files seem to be released on a monthly basis. Refer to [the official website of the dataset](https://www.trade.gov/i-94-arrivals-program) for more information on detailed release schedule.\n",
    "\n",
    "It seems that the U.S. City Demographic Data is expected to be updated in [every 10 years](https://demographics.coopercenter.org/guide-to-publicly-available-demographic-data), which implies this dataset is relatively static, and may not be updated for years.\n",
    "\n",
    "Other additional datasets being used in this project depends on the update release schedule of The International Trade Administration (ITA), U.S. Department of Commerce, because these data (embedded in I94_SAS_Labels_Descriptions.SAS file) were part of the paid dataset purchased from ITA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "When the size of the data was **increased by 100x**, it means the data would be expected to grow exponentially. There are some technologies that can simultaneously allow nearly infinite storage expansion as well as provide adequate scalability, like [Apache Cassandra](https://cassandra.apache.org/_/case-studies.html) NoSQL database, and it can be deployed on-premises. If we prefer to use cloud-based services, then AWS EMR (cluster mode Spark) and AWS S3 (cloud-based storage) would be a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "When the data populates a dashboard that must be **updated on a daily basis by 7am every day**, it means the execution of the ETL pipelines should be scheduled and automated. The [Apache Airflow](https://airflow.apache.org/) introduced in the previous courses should serve this situation very well, but whether the Airflow is deployed on-premises or cloud-based depends on the budget we have. And remember to schedule the ETL tasks based on the recorded execution time of the current ETL pipelines - for example, if you ETL pipelines take more than 1 hour to finish, then you may need to schedule your tasks to start at least 2 hours before 7am every day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "When the database needed to be **accessed by more than 100 people**, it means the concurrency control becomes an issue thet needs to be looked after. It may be necessary to migrate part or all the data to some [ACID](https://en.wikipedia.org/wiki/ACID)-compliant databases to ensure all the online users can get the expected, desirable results at any time they access the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
